BATCH_SIZE = 32
LEARNING_RATE = 1e-3
WEIGHT_DECAY = 1e-4

MNISTDataloader.root = 'data'
MNISTDataloader.batch_size = %BATCH_SIZE

Adam.lr = %LEARNING_RATE
Adam.weight_decay = %WEIGHT_DECAY

StepLR.step_size = 10
StepLR.gamma = 0.1

MNISTTrainer.model_cls = @LeNet
MNISTTrainer.optimizer_cls = @Adam
MNISTTrainer.scheduler_cls = @StepLR
MNISTTrainer.dataloader_cls = @MNISTDataloader
MNISTTrainer.num_epochs = 40

train.trainer = @MNISTTrainer()

log_params.learning_rate = %LEARNING_RATE
log_params.batch_size = %BATCH_SIZE
log_params.weight_decay = %WEIGHT_DECAY
